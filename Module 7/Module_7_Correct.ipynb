{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PySpark MLlib API provides a DecisionTreeClassifier model to implement classification with decision tree method.\n",
    "\n",
    "A decision tree method is one of the well known and powerful supervised machine learning algorithms that can be used for classification and regression tasks. It is a tree-like, top-down flow learning method to extract rules from the training data. The branches of the tree are based on certain decision outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#create spark context\n",
    "sqlCtx = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n",
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "We use ch6_training dataset to perform classification and it can be easily loaded from the DSPR_Data_Sets folder. Below code explains how to load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column types: [('Marital status', 'string'), ('Income', 'string'), ('Cap_Gains_Losses', 'string')]\n",
      "Rows : 18761\n",
      "column types: [('Marital status', 'string'), ('Income', 'string'), ('Cap_Gains_Losses', 'string'), ('Cap_Gains_Losses_Double', 'double')]\n",
      "+--------------+------+----------------+-----------------------+\n",
      "|Marital status|Income|Cap_Gains_Losses|Cap_Gains_Losses_Double|\n",
      "+--------------+------+----------------+-----------------------+\n",
      "| Never-married| <=50K|        0.021740|                0.02174|\n",
      "|      Divorced| <=50K|        0.000000|                    0.0|\n",
      "|       Married| <=50K|        0.000000|                    0.0|\n",
      "|       Married| <=50K|        0.000000|                    0.0|\n",
      "|       Married| <=50K|        0.000000|                    0.0|\n",
      "|       Married|  >50K|        0.000000|                    0.0|\n",
      "| Never-married|  >50K|        0.140841|               0.140841|\n",
      "|       Married|  >50K|        0.051781|               0.051781|\n",
      "|       Married|  >50K|        0.000000|                    0.0|\n",
      "| Never-married| <=50K|        0.000000|                    0.0|\n",
      "+--------------+------+----------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ch6_training = sqlCtx.read.option('header','true').options(delimiter=\",\").csv('DSPR_Data_Sets/adult_ch6_training')\n",
    "print(\"column types:\", ch6_training.dtypes)\n",
    "print(\"Rows :\", ch6_training.count())\n",
    "# Use withColumn() to convert the data type of a DataFrame column,\n",
    "# This function takes column name you wanted to convert as a first argument and\n",
    "# for the second argument apply the casting method cast() with DataType on the column.\n",
    "ch6_training = ch6_training.withColumn(\"Cap_Gains_Losses_Double\",func.col(\"Cap_Gains_Losses\").cast(DoubleType()))\n",
    "print(\"column types:\", ch6_training.dtypes)\n",
    "\n",
    "# Show Data Frame\n",
    "ch6_training.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Marital status', 'string'), ('Income', 'string'), ('Cap_Gains_Losses', 'string'), ('Cap_Gains_Losses_Double', 'double'), ('indexedLabel', 'double')]\n",
      "+--------------+------+----------------+-----------------------+------------+\n",
      "|Marital status|Income|Cap_Gains_Losses|Cap_Gains_Losses_Double|indexedLabel|\n",
      "+--------------+------+----------------+-----------------------+------------+\n",
      "| Never-married| <=50K|        0.021740|                0.02174|         0.0|\n",
      "|      Divorced| <=50K|        0.000000|                    0.0|         0.0|\n",
      "|       Married| <=50K|        0.000000|                    0.0|         0.0|\n",
      "|       Married| <=50K|        0.000000|                    0.0|         0.0|\n",
      "|       Married| <=50K|        0.000000|                    0.0|         0.0|\n",
      "|       Married|  >50K|        0.000000|                    0.0|         1.0|\n",
      "| Never-married|  >50K|        0.140841|               0.140841|         1.0|\n",
      "|       Married|  >50K|        0.051781|               0.051781|         1.0|\n",
      "|       Married|  >50K|        0.000000|                    0.0|         1.0|\n",
      "| Never-married| <=50K|        0.000000|                    0.0|         0.0|\n",
      "+--------------+------+----------------+-----------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the Income column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "incomeIndexer = StringIndexer(inputCol=\"Income\", outputCol=\"indexedLabel\", handleInvalid=\"skip\")\n",
    "\n",
    "# Run the indexer.\n",
    "incomeIndexer_fit = incomeIndexer.fit(ch6_training)\n",
    "\n",
    "# Transformer : A Transformer is an algorithm which can transform one DataFrame into another DataFrame .\n",
    "# E.g., an ML model is a Transformer which transforms DataFrame with features into a DataFrame with predictions.\n",
    "dataframe_training = incomeIndexer_fit.transform(ch6_training)\n",
    "print(dataframe_training.dtypes)\n",
    "\n",
    "# Show Data Frame\n",
    "dataframe_training.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the Marital status column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "maritalIndexer = StringIndexer(inputCol=\"Marital status\", outputCol=\"Marital feature\")\n",
    "\n",
    "# Run the indexer.\n",
    "maritalIndexer_fit = maritalIndexer.fit(dataframe_training)\n",
    "\n",
    "# Transformer : A Transformer is an algorithm which can transform one DataFrame into another DataFrame .\n",
    "# E.g., an ML model is a Transformer which transforms DataFrame with features into a DataFrame with predictions.\n",
    "dataframe_training = maritalIndexer_fit.transform(dataframe_training)\n",
    "print(dataframe_training.dtypes)\n",
    "\n",
    "# Show Data Frame\n",
    "dataframe_training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vector features,\n",
    "# Fit on whole dataset to include all features\n",
    "featureAssembler = VectorAssembler(inputCols = ['Cap_Gains_Losses_Double', 'Marital feature'] , outputCol='features')\n",
    "dataframe_training = featureAssembler.transform(dataframe_training)\n",
    "dataframe_training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_training_output = dataframe_training.select(['indexedLabel', 'features'])\n",
    "dataframe_training_output.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ch6_test = sqlCtx.read.option('header','true').options(delimiter=\",\").csv('DSPR_Data_Sets/adult_ch6_test')\n",
    "ch6_test = ch6_test.withColumn(\"Cap_Gains_Losses_Double\",func.col(\"Cap_Gains_Losses\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "incomeIndexer_test = StringIndexer(inputCol=\"Income\", outputCol=\"indexedLabel\")\n",
    "incomeIndexer_fit = incomeIndexer_test.fit(ch6_test)\n",
    "dataframe_test = incomeIndexer_fit.transform(ch6_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "maritalIndexer = StringIndexer(inputCol=\"Marital status\", outputCol=\"Marital feature\")\n",
    "maritalIndexer_fit = maritalIndexer.fit(dataframe_test)\n",
    "dataframe_test = maritalIndexer_fit.transform(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "featureAssembler = VectorAssembler(inputCols = ['Cap_Gains_Losses_Double', 'Marital feature'] , outputCol='features')\n",
    "dataframe_test = featureAssembler.transform(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_test = dataframe_test.select(['indexedLabel', 'features'])\n",
    "dataframe_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"indexedLabel\")\n",
    "\n",
    "# Fit dataframe to the DecisionTreeClassifier\n",
    "dtc = dtc.fit(dataframe_training)\n",
    "\n",
    "# Make predictions.\n",
    "pred = dtc.transform(dataframe_test)\n",
    "pred.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model evaluation\n",
    "While there are many different types of classification algorithms, the evaluation of classification models all share similar principles. In a supervised classification problem, there exists a true output and a model-generated predicted output for each data point. For this reason, the results for each data point can be assigned to one of four categories:\n",
    "\n",
    "* True Positive (TP) - label is positive and prediction is also positive\n",
    "* True Negative (TN) - label is negative and prediction is also negative\n",
    "* False Positive (FP) - label is negative but prediction is positive\n",
    "* False Negative (FN) - label is positive but prediction is negative\n",
    "\n",
    "source : https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html#:~:text=the%20F%2Dmeasure.-,Binary%20classification,-Binary%20classifiers%20are\n",
    "\n",
    "#### F1 score\n",
    "is defined as the harmonic mean between precision and recall. It is used as a statistical measure to rate performance. In other words, an F1-score (from 0 to 9, 0 being lowest and 9 being the highest) is a mean of an individual's performance, based on two factors i.e. precision and recall.\n",
    "\n",
    "#### Recall\n",
    "literally is how many of the true positives were recalled (found), i.e. how many of the correct hits were also found.\n",
    "\n",
    "#### Precision\n",
    "is how many of the returned hits were true positive i.e. how many of the found were correct hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tp = pred.filter((pred.indexedLabel == 1) & (pred.prediction == 1)).count()\n",
    "tn = pred.filter((pred.indexedLabel == 0) & (pred.prediction == 0)).count()\n",
    "fp = pred.filter((pred.indexedLabel == 0) & (pred.prediction == 1)).count()\n",
    "fn = pred.filter((pred.indexedLabel == 1) & (pred.prediction == 0)).count()\n",
    "\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "\n",
    "a = ((tp + tn)/pred.count())\n",
    "r = float(tp) / (tp + fn)\n",
    "p = float(tp) / (tp + fp)\n",
    "f1 = 2 * ((p * r)/(p + r))\n",
    "\n",
    "print(\"Accuracy:\", a)\n",
    "print(\"Recall:\", r)\n",
    "print(\"Precision:\", p)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data\n",
    "\n",
    "We use ch3_training dataset to perform classification and it can be easily loaded from the DSPR_Data_Sets folder. Below code explains how to load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "ch3_read = sqlCtx.read.option('header','true').options(delimiter=\",\").csv('DSPR_Data_Sets/adult_ch3_training')\n",
    "\n",
    "ch3 = ch3_read.withColumn(\"age\",func.col(\"age\").cast(DoubleType()))\n",
    "ch3 = ch3.select(\"*\").withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "ch3_select = ch3.select([\"id\", \"age\", \"marital-status\", \"income\"])\n",
    "\n",
    "ch3_training, ch3_test = ch3_select.randomSplit([0.7, 0.3])\n",
    "\n",
    "print(\"Training count :\", ch3_training.count())\n",
    "print(\"Test count :\", ch3_test.count())\n",
    "\n",
    "ch3_training.show(5)\n",
    "ch3_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the Income column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "incomeIndexer = StringIndexer(inputCol=\"income\", outputCol=\"indexedLabel\")\n",
    "\n",
    "incomeIndexer_fit = incomeIndexer.fit(ch3_training)\n",
    "\n",
    "dataframe_training = incomeIndexer_fit.transform(ch3_training)\n",
    "\n",
    "dataframe_training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the Marital status column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "maritalIndexer = StringIndexer(inputCol=\"marital-status\", outputCol=\"Marital feature\")\n",
    "\n",
    "# Run the indexer.\n",
    "maritalIndexer_fit = maritalIndexer.fit(dataframe_training)\n",
    "\n",
    "# Transformer : A Transformer is an algorithm which can transform one DataFrame into another DataFrame .\n",
    "# E.g., an ML model is a Transformer which transforms DataFrame with features into a DataFrame with predictions.\n",
    "dataframe_training = maritalIndexer_fit.transform(dataframe_training)\n",
    "print(dataframe_training.dtypes)\n",
    "\n",
    "# Show Data Frame\n",
    "dataframe_training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vector features,\n",
    "# Fit on whole dataset to include all features\n",
    "featureAssembler = VectorAssembler(inputCols = ['age', 'Marital feature'] , outputCol='features')\n",
    "dataframe_training = featureAssembler.transform(dataframe_training)\n",
    "dataframe_training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_training_output = dataframe_training.select(['indexedLabel', 'features'])\n",
    "dataframe_training_output.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "incomeIndexer = StringIndexer(inputCol=\"income\", outputCol=\"indexedLabel\")\n",
    "\n",
    "incomeIndexer_fit = incomeIndexer.fit(ch3_test)\n",
    "\n",
    "dataframe_test = incomeIndexer_fit.transform(ch3_test)\n",
    "\n",
    "dataframe_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the Marital status column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "maritalIndexer = StringIndexer(inputCol=\"marital-status\", outputCol=\"Marital feature\")\n",
    "\n",
    "# Run the indexer.\n",
    "maritalIndexer_fit = maritalIndexer.fit(dataframe_test)\n",
    "\n",
    "# Transformer : A Transformer is an algorithm which can transform one DataFrame into another DataFrame .\n",
    "# E.g., an ML model is a Transformer which transforms DataFrame with features into a DataFrame with predictions.\n",
    "dataframe_test = maritalIndexer_fit.transform(dataframe_test)\n",
    "print(dataframe_test.dtypes)\n",
    "\n",
    "# Show Data Frame\n",
    "dataframe_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# vector features,\n",
    "# Fit on whole dataset to include all features\n",
    "featureAssembler = VectorAssembler(inputCols = ['age', 'Marital feature'] , outputCol='features')\n",
    "dataframe_test = featureAssembler.transform(dataframe_test)\n",
    "dataframe_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_test_output = dataframe_test.select(['indexedLabel', 'features'])\n",
    "dataframe_test_output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"indexedLabel\")\n",
    "\n",
    "# Fit dataframe to the DecisionTreeClassifier\n",
    "dtc = dtc.fit(dataframe_training)\n",
    "\n",
    "# Make predictions.\n",
    "pred = dtc.transform(dataframe_test)\n",
    "pred.show(10)\n",
    "\n",
    "## Search for rawPrediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model evaluation\n",
    "While there are many different types of classification algorithms, the evaluation of classification models all share similar principles. In a supervised classification problem, there exists a true output and a model-generated predicted output for each data point. For this reason, the results for each data point can be assigned to one of four categories:\n",
    "\n",
    "* True Positive (TP) - label is positive and prediction is also positive\n",
    "* True Negative (TN) - label is negative and prediction is also negative\n",
    "* False Positive (FP) - label is negative but prediction is positive\n",
    "* False Negative (FN) - label is positive but prediction is negative\n",
    "\n",
    "source : https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html#:~:text=the%20F%2Dmeasure.-,Binary%20classification,-Binary%20classifiers%20are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tp = pred.filter((pred.indexedLabel == 1) & (pred.prediction == 1)).count()\n",
    "tn = pred.filter((pred.indexedLabel == 0) & (pred.prediction == 0)).count()\n",
    "fp = pred.filter((pred.indexedLabel == 0) & (pred.prediction == 1)).count()\n",
    "fn = pred.filter((pred.indexedLabel == 1) & (pred.prediction == 0)).count()\n",
    "\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "\n",
    "a = ((tp + tn)/pred.count()) # a for accuracy\n",
    "r = float(tp) / (tp + fn) # r for recall\n",
    "p = float(tp) / (tp + fp) # p for precision\n",
    "f1 = 2 * ((p * r)/(p + r)) ### f1 for F1 score\n",
    "\n",
    "print(\"Accuracy:\", a)\n",
    "print(\"Recall:\", r)\n",
    "print(\"Precision:\", p)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}